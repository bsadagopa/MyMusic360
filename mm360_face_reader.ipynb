{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyMusic360_face_reader Application\n",
    "#### AI - ML system built using Microsoft Azure FACE API \n",
    "##### System loads user pictures and gets trained.\n",
    "##### Users use cam-login i.e. picture to authenticate into the system\n",
    "##### Along with the credential verification, mm360 system also guages their mood\n",
    "##### mm360_face_reader then sends the user details including mood to the audio selection system.\n",
    "##### Audio selection system will use the mood to play - recommend the music for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cognitive_face as CF\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import sys, getopt, os\n",
    "import requests\n",
    "import json\n",
    "#from cv2 import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** STEPS **<br>\n",
    "*** Detecting faces using the Face - Detect API ***<br>\n",
    "*** Creating PersonGroups using the PersonGroup - Create API *** <br>\n",
    "*** Creating persons using the PersonGroup Person - Create API ***<br>\n",
    "*** Train a PersonGroup using the PersonGroup – Train API ***<br>\n",
    "*** Identifying unknown faces against the PersonGroup using the Face - Identify API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# Init\n",
    "#######\n",
    "subscription_key = '0699e543b5874c18b121d87671317d8a'\n",
    "img_url = './mm360_filename.jpg' \n",
    "root_folder = './group_pictures'\n",
    "\n",
    "# base face_api url\n",
    "uri_base = 'https://southcentralus.api.cognitive.microsoft.com/face/v1.0'\n",
    "\n",
    "# To get some custom data\n",
    "custom_data = {'skb':'Balaji',\n",
    "              'ak':'Andrew',\n",
    "              'sg':'Suswidth',\n",
    "              'ns':'Nikhil',\n",
    "              'nss':'Nishanth',\n",
    "              'jgs':'Jessica',\n",
    "              'rb':'Raji'}\n",
    "emotion_metric = {\n",
    "                0:'anger',\n",
    "                1:'contempt',\n",
    "                2:'disgust',\n",
    "                3:'fear',\n",
    "                4:'happiness',\n",
    "                5:'neutral',\n",
    "                6:'sadness',\n",
    "                7:'surprise'}\n",
    "\n",
    "CF.BaseUrl.set(uri_base)\n",
    "CF.Key.set(subscription_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# getBinaryFileData\n",
    "#######\n",
    "def getBinaryFileData(filename):\n",
    "    # open jpg file as binary file data for intake by the MCS api  \n",
    "    with open(filename, 'rb') as f:\n",
    "        img_data = f.read()\n",
    "        return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take_picture():\n",
    "#     cam = cv2.VideoCapture(0)   # 0 -> index of camera\n",
    "#     s, img = cam.read()\n",
    "#     if s:    # frame captured without any errors\n",
    "#        namedWindow(\"cam-test\")\n",
    "#        imshow(\"cam-test\",img)\n",
    "#        destroyWindow(\"cam-test\")\n",
    "#        imwrite(\"mm360_filename.jpg\",img) #save image\n",
    "\n",
    "#     # close the camera    \n",
    "#     cam.release()\n",
    "#     print(\"Succesfully took mm360_filename.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# take_picture\n",
    "#######\n",
    "def take_picture():\n",
    "    # Camera 0 is the integrated web cam on my netbook\n",
    "    camera_port = 0\n",
    "\n",
    "    #Number of frames to throw away while the camera adjusts to light levels\n",
    "    ramp_frames = 30\n",
    "    \n",
    "    try:\n",
    " \n",
    "        # Now we can initialize the camera capture object with the cv2.VideoCapture class.\n",
    "        # All it needs is the index to a camera port.\n",
    "        camera = cv2.VideoCapture(camera_port)\n",
    "\n",
    "        # Captures a single image from the camera and returns it in PIL format\n",
    "        def get_image():\n",
    "            # read is the easiest way to get a full image out of a VideoCapture object.\n",
    "            retval, im = camera.read()\n",
    "            return im\n",
    "\n",
    "        # Ramp the camera - these frames will be discarded and are only used to allow v4l2\n",
    "        # to adjust light levels, if necessary\n",
    "        for i in range(ramp_frames):\n",
    "            temp = get_image()\n",
    "        print(\"Taking image...\")\n",
    "        \n",
    "        # Take the actual image we want to keep\n",
    "        camera_capture = get_image()\n",
    "        file = \"./mm360_filename.jpg\"\n",
    "        \n",
    "        # A nice feature of the imwrite method is that it will automatically choose the\n",
    "        # correct format based on the file extension you provide. Convenient!\n",
    "        cv2.imwrite(file, camera_capture)\n",
    "        print(f'saving {file}..')\n",
    "\n",
    "        # You'll want to release the camera, otherwise you won't be able to create a new\n",
    "        # capture object until your script exits\n",
    "        del(camera)\n",
    "    except Exception as e:\n",
    "        print(f\"EXCETION in take_picture::{e}\")\n",
    "        del(camera)\n",
    "    print(f'Campleted taking picture.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# getRectangle\n",
    "#######\n",
    "#Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary['faceRectangle']\n",
    "    left = rect['left']\n",
    "    top = rect['top']\n",
    "    bottom = left + rect['height']\n",
    "    right = top + rect['width']\n",
    "    #return ((left, top), (bottom, right))\n",
    "    return (left,top,bottom,right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Detecting faces using the Face - Detect API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# recogn_from_local_img\n",
    "# detect image (face) method\n",
    "#######\n",
    "def recogn_from_local_img(filename):\n",
    "    #     CF.BaseUrl.set(uri_base)\n",
    "    #     CF.Key.set(subscription_key)\n",
    "    \n",
    "    #     attributes: [Optional] Analyze and return the one or more specified\n",
    "    #         face attributes in the comma-separated string like\n",
    "    #         \"age,gender\". Supported face attributes include age, gender,\n",
    "    #         headPose, smile, facialHair, glasses, emotion, makeup, accessories,\n",
    "    #         occlusion, blur, exposure, noise. Note that each face attribute\n",
    "    #         analysis has additional computational and time cost.\n",
    "    #         attributes='age,gender,emotion'\n",
    "\n",
    "    try:\n",
    "        response = CF.face.detect(filename, attributes='emotion')\n",
    "        print(response)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "#     face_ids = [d['faceId'] for d in response]\n",
    "#     print(face_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# drawRectangeAroungFace\n",
    "#######\n",
    "def drawRectangeAroungFace(img_url):\n",
    "    faces = recogn_from_local_img(img_url)\n",
    "    # print(faces)\n",
    "\n",
    "    #Download the image from the url\n",
    "    img = Image.open(BytesIO(getBinaryFileData(img_url)))\n",
    "\n",
    "    #For each face returned use the face rectangle and draw a red box.\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in faces:\n",
    "        print(getRectangle(face))\n",
    "        draw.rectangle(getRectangle(face), outline='red')\n",
    "        \n",
    "    # #Display the image in the users default image browser.\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(recogn_from_local_img_1(img_url))[0]\n",
    "#match_image(img_url)\n",
    "#getBinaryFileData(img_url)\n",
    "#drawRectangeAroungFace(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Delete a PersonGroup using the PersonGroup – Delete API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# deletePersonGroup\n",
    "#######\n",
    "def deletePersonGroup(personGroupId):\n",
    "    CF.BaseUrl.set(uri_base)\n",
    "    CF.Key.set(subscription_key)\n",
    "    \n",
    "    try:\n",
    "        CF.person_group.delete(personGroupId)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Creating PersonGroups using the PersonGroup - Create API *** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# createPersonGroup\n",
    "#######\n",
    "def createPersonGroup(personImage, personGroupId):\n",
    "    \n",
    "    #BASE_URL = 'https://westus.api.cognitive.microsoft.com/face/v1.0/'\n",
    "    #PERSON_GROUP_ID = personGroupId\n",
    "    CF.BaseUrl.set(uri_base)\n",
    "    CF.Key.set(subscription_key) \n",
    "    \n",
    "    try:\n",
    "        # create person group\n",
    "        CF.person_group.create(personGroupId, personGroupId)\n",
    "        \n",
    "        print(f\"personGroupId = {personGroupId}\")\n",
    "\n",
    "        return personGroupId;\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION :: {e}\")  \n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Creating persons using the PersonGroup Person - Create API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# createPersonGroup\n",
    "#######\n",
    "def createPerson(personGroupId, personName):\n",
    "\n",
    "    try:\n",
    "       \n",
    "        # create person\n",
    "        cust_data = custom_data.get(personName)\n",
    "        if(cust_data == None):\n",
    "            cust_data = 'Hello New User'\n",
    "        response = CF.person.create(personGroupId, \n",
    "                                    personName, \n",
    "                                    cust_data)\n",
    "                                    #f'{personName} person data')\n",
    "        print(f\"RESPONSE={response}\")\n",
    "        # Get person_id from response\n",
    "        person_id = response['personId']\n",
    "        \n",
    "        print(f\"person_id = {person_id}\")\n",
    "\n",
    "        return person_id;\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION :: {e}\")  \n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Add persons using the PersonGroup Person - Create API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# addPersonFace\n",
    "#######\n",
    "def addPersonFace(personImage,\n",
    "                  personGroupId, \n",
    "                  person_id,\n",
    "                  user_name_key,\n",
    "                  personUserData):\n",
    "    try:\n",
    "        #add_face(image, person_group_id, person_id, user_data=None, target_face=None).\n",
    "        #targetFace=left,top,width,height\n",
    "        #\"targetFace=10,10,100,100\"\n",
    "        \n",
    "        tf_rect = personUserData[0]['faceRectangle']\n",
    "        tf_rect_val = f'{tf_rect[\"left\"]},{tf_rect[\"top\"]},{tf_rect[\"width\"]},{tf_rect[\"height\"]}'\n",
    "        print(tf_rect_val)\n",
    "        \n",
    "        cust_data = custom_data.get(user_name_key)\n",
    "        if(cust_data == None):\n",
    "            cust_data = 'Hello New User'\n",
    "        persisted_face_id = CF.person.add_face(personImage, \n",
    "                                               personGroupId, \n",
    "                                               person_id, \n",
    "                                               cust_data,\n",
    "                                               #f'{personGroupId} person data',\n",
    "                                               tf_rect_val)\n",
    "                          \n",
    "\n",
    "        print(f\"CF.person.lists: {CF.person.lists(personGroupId)}\")\n",
    "        print(f\"Sucessfully added \")\n",
    "\n",
    "        return persisted_face_id\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION :: {e}\")  \n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Train a PersonGroup using the PersonGroup – Train API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# trainPersonGroup\n",
    "#######\n",
    "def trainPersonGroup(personGroupId):\n",
    "        try:\n",
    "            CF.person_group.train(personGroupId)\n",
    "            response = CF.person_group.get_status(personGroupId)\n",
    "            status = response['status']\n",
    "\n",
    "            print(f\"STATUS  = {status}\")\n",
    "            return status\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"EXCEPTION :: {e}\")\n",
    "\n",
    "        print(f'Complete training {personGroupId}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Identifying unknown faces against the PersonGroup using the Face - Identify API ***<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# identifyPerson\n",
    "#######\n",
    "def identifyPerson(filename, personGroupId):\n",
    "    try:\n",
    "        response = CF.face.detect(filename, attributes='emotion')\n",
    "        face_ids = [d['faceId'] for d in response]\n",
    "        print(f\"face_ids = {face_ids}\")\n",
    "    \n",
    "        identified_faces = CF.face.identify(face_ids, personGroupId)\n",
    "        print(f\"identified_faces = {identified_faces}\")\n",
    "        # get the emotions for the matching face_ids\n",
    "        responses = []\n",
    "        for d in response:\n",
    "            for ided_face in identified_faces:\n",
    "                if(d['faceId'] == ided_face['faceId']):\n",
    "                    #print(d)\n",
    "                    responses.append({\n",
    "                        'faceId': d['faceId'],\n",
    "                        'candidates':ided_face['candidates'],\n",
    "                        'emotion': d['faceAttributes']['emotion']})\n",
    "            print(responses)\n",
    "        return responses\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION:{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'emotion': {'anger': 0.0,\n",
    "#    'contempt': 0.0,\n",
    "#    'disgust': 0.0,\n",
    "#    'fear': 0.0,\n",
    "#    'happiness': 0.0,\n",
    "#    'neutral': 0.999,\n",
    "#    'sadness': 0.001,\n",
    "#    'surprise': 0.0}\n",
    "# a = [0.0,0.0,0.0,0.0,0.0,0.999,0.001,0.0]\n",
    "# print(max(enumerate(a),key=lambda x: x[1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmotionsAsList(emotion):\n",
    "    emotionList = []\n",
    "    emotionList.append(emotion['anger'])\n",
    "    emotionList.append(emotion['contempt'])\n",
    "    emotionList.append(emotion['disgust'])\n",
    "    emotionList.append(emotion['fear'])\n",
    "    emotionList.append(emotion['happiness'])\n",
    "    emotionList.append(emotion['neutral'])\n",
    "    emotionList.append(emotion['sadness'])\n",
    "    emotionList.append(emotion['surprise'])\n",
    "    \n",
    "    print(emotionList)\n",
    "    return emotionList                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guageEmotionList(emotion):\n",
    "    emotionList = getEmotionsAsList(emotion)\n",
    "    #get the highest number among the mood fields\n",
    "    topEmotion = max(enumerate(emotionList),key=lambda x: x[1])[0]\n",
    "    mood = emotion_metric[topEmotion]\n",
    "    return mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Method to loadi the  user pictures and train MyMusic360 </h3><br>\n",
    "<p>1. Loads the images from root folder</p>\n",
    "<p>1.1 Expects folder structure to be  </p>\n",
    "    start(root) : group_pictures/ <br>\n",
    "    Members folder, must be names with unique member initials:  <br>\n",
    "        group_pictures/skb, group_pictures/sg, group_pictures/ak <br>\n",
    "    Pictures (*.jpg) specific to users under their names folder <br>\n",
    "        skb's pics under group_pictures/skb/*.jpg </p>\n",
    "<p>2 Creates PersonGroup for root folder </p>\n",
    "<p>3 Creates Person (s) for each member folder </p>\n",
    "<p>4 Adds pics under each Person </p>\n",
    "<p>5 Trains the PersonGroup </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# loadGroupImages\n",
    "#\n",
    "# main method to load the images of group members and train\n",
    "# so any future login can be identified\n",
    "#######\n",
    "def loadGroupImages(folder, personGroupId):\n",
    "    # contains [{personId: [persistent_face_ids]}]\n",
    "    # eg: [{skb:[face_id_1, face_id2]}, {sg:[face_id_1, face_id2]}, {ak:[face_id_1, face_id2]}]\n",
    "    \n",
    "    personGroup = {}\n",
    "    personList = []\n",
    "    persistentPersonFaceIDList = []\n",
    "    personId = ''\n",
    "    persistentPersonFaceID = ''\n",
    "    loop_count = 0\n",
    "    file_loop_count = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        current_folder = ''\n",
    "        for dir in dirs:\n",
    "            personGroup[dir] = {}\n",
    "        \n",
    "        for file in files:\n",
    "            fullpath = os.path.join(root, file)\n",
    "            \n",
    "            ## Sleep to stay under the service restriction\n",
    "            time.sleep(10)\n",
    "            \n",
    "            if ((os.path.splitext(fullpath)[1] == '.jpeg') or\n",
    "                (os.path.splitext(fullpath)[1] == '.jpg')):\n",
    "            \n",
    "                # use foldername as the person name\n",
    "                foldername = os.path.split(fullpath)[0].split('/')[2]\n",
    "                \n",
    "                personList = personGroup[foldername]\n",
    "                \n",
    "                if(loop_count == 0):\n",
    "                    try:\n",
    "                        print(\"Starting createPersonGroup\")\n",
    "                        createPersonGroup(file, personGroupId)\n",
    "                        print(\"Finished createPersonGroup\")\n",
    "                    except CF.CognitiveFaceException as e:\n",
    "                        print(e)\n",
    "                        # if PersonGroupExists already exists just add faces to it\n",
    "                        if(e.code == 'PersonGroupExists'):\n",
    "                            print(\"Error PersonGroupExists\")\n",
    "                    loop_count += 1   \n",
    "                try:\n",
    "                    #\n",
    "                    # create Person if does not exist\n",
    "                    #\n",
    "                    print(\"Starting createPerson()\")\n",
    "                    \n",
    "                    # create a new key in the dict for the first entry \n",
    "                    # for every user/person\n",
    "                    person_dict = personGroup.get(foldername)\n",
    "                    if(len(person_dict) == 0):\n",
    "                        print(f\"****** Creating NEW personID ***\") \n",
    "                        personId = createPerson(personGroupId, foldername)\n",
    "                        person_dict = {personId:[]}\n",
    "                        personGroup[foldername] = person_dict\n",
    "                    else:\n",
    "                        print(f\"****** FOUUNd personID ***\")\n",
    "                        print(f\"personId = {person_dict}\")\n",
    "                  \n",
    "                    print(\"Finished createPerson()\")\n",
    "\n",
    "                    #\n",
    "                    # Add Person(s) face\n",
    "                    #\n",
    "                    print(\"Starting addPersonFace()\")\n",
    "                    personId = list(person_dict.keys())[0]\n",
    "                    print(f\"personId = {personId}\")\n",
    "                    persistentPersonFaceID = addPersonFace(fullpath, \n",
    "                                                  personGroupId, \n",
    "                                                  personId,\n",
    "                                                  foldername, \n",
    "                                                  recogn_from_local_img(fullpath))\n",
    "                    persistentIdsList = person_dict.get(personId)\n",
    "                    persistentIdsList.append(persistentPersonFaceID)\n",
    "                    person_dict[personId] = persistentIdsList\n",
    "                    print(\"Finished addPersonFace()\")     \n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"EXCEPTION in LOOP-createPerson :: {e}\")\n",
    "                file_loop_count += 1\n",
    "                    \n",
    "    print(f\"ALL_DONE +++ {personGroup}\")  \n",
    "    #\n",
    "    # Train the group\n",
    "    #\n",
    "    try:\n",
    "        status = trainPersonGroup(personGroupId)\n",
    "        # print Status\n",
    "        print(f\"STATUS: {status}\")\n",
    "    except CF.CognitiveFaceException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to communicate to the Spotify component.\n",
    "### Take the Pic and check with load images to predict the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps :\n",
    "<b> Take Pic <br> \n",
    "<b> Save pic locally <br> \n",
    "<b> identify the person from the stored collection <br> \n",
    "<b> guage the mood of the person - single value, highest from emotion will be used <br>\n",
    "<b> call spotify wrapper layer of the software , pass the user-info: user_id, mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleMM_User(groupUserId):\n",
    "    try:\n",
    "        # Take Pic\n",
    "        take_picture()\n",
    "        # identify the person from the stored collection \n",
    "        responses = identifyPerson(img_url, groupUserId)\n",
    "        person_id = responses[0]['candidates'][0]['personId']\n",
    "        # guage the mood of the person - single value, highest from emotion will be used \n",
    "        print(responses[0]['emotion'])\n",
    "        mood = guageEmotionList(responses[0]['emotion'])\n",
    "        print(f\"Mood = {mood}\")\n",
    "        info = CF.person.get(groupUserId, person_id)\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION-handleMM_User::{e}\")\n",
    "        print(f\"!! FATAL, Communication to comm_To_mm360_wrapper did not occur !!\")\n",
    "        return\n",
    "    \n",
    "    comm_To_mm360_wrapper = {\n",
    "        'userName':info['name'],\n",
    "        'userData':info['userData'],\n",
    "        'userCurrentMood':mood\n",
    "    }\n",
    "\n",
    "    print(f\"Welcome USER ==> {info['userData']}, your mood is {mood}\")\n",
    "    print(f\"data_sent_to_music(spotify)_wrapper = {comm_To_mm360_wrapper}\")\n",
    "    \n",
    "    return comm_To_mm360_wrapper\n",
    "    #\n",
    "    #  TBD -- CAll to Spotify Wrapper layer\n",
    "    #\n",
    "    # call_mm360_spotify_wrapper({comm_To_mm360_wrapper})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main start function call to load the images and be ready to recognize pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loadGroupImages('./group_pictures', \"mm360_group1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Running the visual login and mood capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the user login i.e. photo capture for authentication and mood capture\n",
    "# user detail name, credentials and mood will be sent to the music wrapper (spotify) component\n",
    "#handleMM_User()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commandline MyMusic360 Aplication start code\n",
    "\n",
    "### Usage will be from mm360_app.py run importing this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===WELCOME TO MYMUSIC360===\n",
      "\n",
      "Usage: mm360_face_reader.py [--help | --load-learn | --my_music]\n",
      "Or\n",
      "mm360_face_reader.py [-h | -l| -m]\n",
      "\n",
      "NOTE OF CAUTION::\n",
      "\n",
      "before running --load-learn, please setup all the folders properly: \n",
      "setup folder <group_pictures>\n",
      "subfolders, one fore each person, group_pictures/<sub-folders>\n",
      "Lastly, load the training pictures for persons under the appropriate subfolders\n",
      "After setup in complete,\n",
      "run load-learn first\n",
      "usage: ./mm360_face_reader.py --load-learn\n",
      "Now you are all set to enjoy MyMusic, by running, \n",
      "usage: ./mm360_face_reader.py --my_music\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys, getopt, os\n",
    "import mm360_face_reader as mm360\n",
    "\n",
    "def usage():\n",
    "\tos.system('clear')\n",
    "\tprint(\"=== WELCOME TO MYMUSIC360 ===\\n\")\n",
    "\tprint('Usage: mm360_face_reader.py [--help | --load-learn <personGroupId> | --my_music <personGroupId> --root_folder <image_root_folder>]')\n",
    "\tprint('Or')\n",
    "\tprint('mm360_face_reader.py [-h | -l <personGroupId> | -m  <personGroupId> | -f <image_root_folder>]')\n",
    "\tprint('\\nNOTE OF CAUTION::\\n')\n",
    "\tprint('before running --load-learn, please setup all the folders properly: ')\n",
    "\tprint('setup folder <group_pictures>')\n",
    "\tprint('subfolders, one fore each person, group_pictures/<sub-folders>')\n",
    "\tprint('Lastly, load the training pictures for persons under the appropriate subfolders')\n",
    "\tprint('After setup in complete,')\n",
    "\tprint('run load-learn first')\n",
    "\tprint('usage: ./mm360_face_reader.py --load-learn')\n",
    "\tprint('Now you are all set to enjoy MyMusic, by running, ')\n",
    "\tprint('usage: ./mm360_face_reader.py --my_music')\n",
    "\tprint(f\"mm360_face_reader assumes default root folder ./group_pictures \")\n",
    "\tprint(f\"To override the default root_folder use, --root_folder option\")\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "\tload_learn = False\n",
    "\tmy_music = False\n",
    "\tpersonGroupId = ''\n",
    "\troot_folder = ''\n",
    "\n",
    "\n",
    "\ttry:\n",
    "\t\topts, args = getopt.getopt(argv,\"hf:l:m:\",[\"help\", \"load-learn=\", \"my_music=\", \"root_folder=\"])\n",
    "\t\tif(len(opts) == 0):\n",
    "\t\t\tusage()\n",
    "\t\t\tsys.exit()\n",
    "\texcept getopt.GetoptError as e:\n",
    "\t\tprint(f\"{e}\")\n",
    "\t\t# usage()\n",
    "\t\tsys.exit(2)\n",
    "\n",
    "\tfor opt, arg in opts:\n",
    "\t\tif opt in (\"-h\" , \"--help\"):\n",
    "\t\t\tusage()\n",
    "\t\t\tsys.exit()\n",
    "\t\telif opt in (\"-l\", \"--load-learn\"):\n",
    "\t\t\tload_learn = True\n",
    "\t\t\tpersonGroupId = arg\n",
    "\t\t\tprint(f\"loadGroupImages({root_folder},{personGroupId})\")\n",
    "\t\t\tmm360.loadGroupImages(root_folder, personGroupId)\n",
    "\t\telif opt in (\"-m\", \"--my_music\"):\n",
    "\t\t\tmy_music = True\n",
    "\t\t\tpersonGroupId = arg\n",
    "\t\t\tprint(f\"handleMM_User({personGroupId})\")\n",
    "\t\t\tmm360.handleMM_User(personGroupId)\n",
    "\t\telif opt in (\"-f\", \"--root_folder\"):\n",
    "\t\t\troot_folder = arg\n",
    "\t\telse:\n",
    "\t\t\tusage()\n",
    "\t\t\tsys.exit()\n",
    "\n",
    "\tprint(f\"load_learn = {load_learn}\")\n",
    "\tprint(f\"music-begin = {my_music}\")\n",
    "\tprint(f\"personGroupId = {personGroupId}\")\n",
    "\tprint(f\"Root Folder = {root_folder}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skb_group_id = createPersonGroup('./group_pictures/skb/skb2.jpg',\n",
    "#                                      \"mm360_group1\")\n",
    "# skb_group_id\n",
    "# balaji_client_id = createPerson(\"mm360_group1\", \"ak\")\n",
    "# \n",
    "# img_url = './group_pictures/ak/ak_pic2.jpeg'\n",
    "# addPersonFace(img_url, \n",
    "#               \"mm360_group1\", \n",
    "#               \"94e18f3b-a394-4f12-b9ec-01b8b9c03e9d\", \n",
    "#               \"ak\",\n",
    "#               recogn_from_local_img(img_url))\n",
    "# trainPersonGroup(\"mm360_group1\")\n",
    "#deletePersonGroup(\"skb_family_group\")\n",
    "# deletePersonGroup(\"mm360_group1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take_picture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# responses = identifyPerson('mm360_filename.jpg', \"mm360_group1\")\n",
    "# person_id = responses[0]['candidates'][0]['personId']\n",
    "# print(responses[0]['emotion'])\n",
    "# mood = guageEmotionList(responses[0]['emotion'])\n",
    "# print(f\"Mood = {mood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = CF.person.get(\"mm360_group1\", person_id)\n",
    "\n",
    "# print(f\"Welcome USER ==> {info['userData']}, your mood is {mood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CF.person.get('mm360_group1', person_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'personId': 'b02af79c-4d89-4cd0-bafe-7327259f161a', 'persistedFaceIds': ['25c7fa79-4009-42bb-ace6-52db30227f7b', '665b83e3-c445-433f-b1ce-13927e9427d9', 'a7b18ee1-3a7e-4f4f-9f5a-bf849a7ccb00', 'c3c55555-2fbb-41d7-9dc7-19678650595e'], 'name': 'skb', 'userData': 'Balaji'}, {'personId': 'b1c3108f-4576-41e5-806a-fa64642f9f7e', 'persistedFaceIds': ['1416880d-752f-4473-ad31-64c293bb39dd', '406d1457-6f65-4120-9239-a92328efc567'], 'name': 'ak', 'userData': 'Andrew'}]\n"
     ]
    }
   ],
   "source": [
    "print(CF.person.lists(\"mm360_group1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'succeeded',\n",
       " 'createdDateTime': '9/14/2018 10:28:48 PM',\n",
       " 'lastActionDateTime': '09/14/2018 22:28:48',\n",
       " 'message': None}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CF.person_group.get_status(\"mm360_group1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test blocks\n",
    "#take_picture()\n",
    "#recogn_from_local_img(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faces = identifyPerson('mm360_filename_2.jpg', \"mm360_group1\")\n",
    "#print(faces)\n",
    "#identifyPerson('mm360_filename_3.jpg', \"mm360_group1\")\n",
    "#identifyPerson('mm360_filename.jpg', \"mm360_group1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faces[0]['candidates'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CF.person.get(\"mm360_group1\", '315369e7-7683-44ea-888e-b8e160d6717d')['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = CF.face.detect('./mm360_filename.jpg', attributes='emotion')\n",
    "# print(response[0]['faceAttributes']['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses = identifyPerson('mm360_filename.jpg', \"mm360_group1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
